# -*- coding: utf-8 -*-
'''
Recognition Model Designed for Radar-Based Human Motion Direction Determination (HMDD)
'''
# Former Author: Lerbron.
# Improved By: JoeyBG.
# Date: 2025.7.22.
# Platform: Python 3.7, paddlepaddle 3.0.0.
# Affiliation: Beijing Institute of Technology.
# 
# Network Structure:
#   - The neural network model features a three-stage hierarchical architecture for image processing, 
#       starting with a Stem module that converts the input image $H \times W \times 3$ into a feature map $H/8 \times W/8 \times C_1$. 
#       Each stage employs multiple SBCFormer Blocks that combine local feature extraction through a Mixer-GELU module 
#       and global feature extraction via a multi-head attention (MAttn) mechanism, which includes projection, convolution, 
#       and attention operations to integrate local and global contexts. The model progressively downsamples the feature maps 
#       in subsequent stages to $H/16 \times W/16 \times C_2$ and $H/32 \times W/32 \times C_3$, 
#       enhancing feature depth while reducing spatial resolution. 
#       The final output is generated by applying Global Pooling to the last stage's feature map, followed by a Linear layer, 
#       enabling the model to effectively capture multi-scale representations for tasks requiring detailed image understanding.
#
# Modules Description:
#   - Stem: A convolutional block that downsamples the input image and extracts initial features.
#   - SBCFormer Block: A block that combines local and global feature extraction.
#   - Global Pooling: A pooling operation that aggregates feature maps across the spatial dimensions.
#   - Linear: A fully connected layer for classification.
#   - MAttn: Multi-head attention mechanism for global feature extraction.
#   - Mixer-GELU: A combination of convolution and GELU activation for local feature extraction.
#   - Conv2d: A convolutional layer for local feature extraction.
#   - GELU: A non-linear activation function.
#
# Usage:
#   - This script can be used to train and evaluate a recognition model for radar-based HMDD tasks. 
#   - The model can be integrated with radar signal processing algorithms to extract human motion direction from radar data.
#
# Dataset Used:
#   - The model is trained and evaluated using the Radar_Based_HMDD_8Classes_XX datasets. 
#       Dataset path: data/data350917/Feature_Enhanced_Dataset_OS.zip.
#   - The datasets are preprocessed and feature-augmented to match the input requirements of this model.
#   - Make sure the size of the input image matches the first layer of network and the number of classes is set to 8.

# Necessary libraries input for code running.
# %matplotlib inline
import paddle
import numpy as np
import matplotlib.pyplot as plt
from paddle.vision.datasets import Cifar10
from paddle.vision.transforms import Compose, Normalize, Transpose, Resize, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter
from paddle.io import Dataset, DataLoader
from paddle import nn
from paddle.nn import CrossEntropyLoss
import paddle.nn.functional as F
import paddle.vision.transforms as transforms
import os
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
import itertools
import random
import cv2 # For reasons that are unclear, network training does not work if the cv2 library is not introduced.
import time
from sklearn.metrics import confusion_matrix

# Import supporting scripts.
from HMDD_Model_Python.models import *

# Initialization of the Python script.
print("---------- Author: © JoeyBG © ----------")
# Execution the training with GPU of number 0.
# paddle.device.set_device('gpu:0')
# Excution the training with CPU.
paddle.device.set_device('cpu')

'''
Data Augmentation and Normalization
'''
# Using data augmentation and normalization during training.
# train_tfm = transforms.Compose([
#     transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),
#     transforms.ColorJitter(brightness=0.2,contrast=0.2, saturation=0.2),
#     transforms.RandomHorizontalFlip(0.5),
#     transforms.RandomRotation(20),
#     transforms.ToTensor(),
#     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
# ])
# During testing, we only need to resize and normalize the input image.
# test_tfm = transforms.Compose([
#     transforms.Resize((224, 224)),
#     transforms.ToTensor(),
#     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
# ])
# Define the uniform transformations for both training and validation data augmentation.
Estimation_Resolution = 224 # Define the resolution of input images. This parameter can be found in MATLAB feature augmentation script.
transform = transforms.Compose([
    transforms.Resize((Estimation_Resolution, Estimation_Resolution)),
    # Considering the specificity of radar images, here we may not use random contrast data augmentation.
    # ColorJitter(0.4, 0.4, 0.4), 
    # We are not suggesting to mix up images in validation or testing sets.
    # paddlex.transforms.MixupImage(),
    # Highly not recommended to do random flip in data augmentation.
    # transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

'''
Parameter Definition
'''
# Path definition.
data_dir = 'Open_Source_Dataset/Feature_Enhanced_Dataset_OS' # Define the path to your dataset.
work_path = 'HMDD_Model_Python/work/model' # Define the path for saving model.

# Training parameters.
learning_rate = 0.00147 # Learning rate for training.
n_epochs = 30 # Number of epochs for training.
train_ratio = 0.8 # Ratio of training data to total dataset.
batch_size = 256 # Batch size predefined for training and validation dataloader.
num_classes = 8 # Number of classes in the dataset.
# paddle.seed(42) # Set random seed for reproducibility.
# np.random.seed(42)

'''
Dataset Construction
'''
# Define a custom dataset class.
class ImageDataset(paddle.io.Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform

    def __getitem__(self, index):
        img_path, label = self.dataset[index]
        img = cv2.imread(img_path)
        if self.transform:
            img = self.transform(img)
        return img, label

    def __len__(self):
        return len(self.dataset)

# Read the training and validation dataset and split it into two.
dataset = []
label_list = sorted(os.listdir(data_dir))
for label_idx, label in enumerate(label_list):
    label_dir = os.path.join(data_dir, label)
    image_list = os.listdir(label_dir)
    random.shuffle(image_list)
    num_train = int(len(image_list) * train_ratio)
    dataset.extend([(os.path.join(label_dir, img), label_idx) for img in image_list])

# Create an instance of the custom dataset class.
full_dataset = ImageDataset(dataset, transform=transform)

# Calculate the number of samples for train and validation sets.
num_train_samples = int(len(full_dataset) * train_ratio)
num_val_samples = len(full_dataset) - num_train_samples

# Split the dataset into train and validation sets.
train_dataset, val_dataset = paddle.io.random_split(full_dataset, lengths=[num_train_samples, num_val_samples])

# Create data loaders for train and validation sets.
train_loader = paddle.io.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = paddle.io.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
print("Number of Datas in Training Set: %d" % len(train_dataset))
print("Number of Datas in Validation Set: %d" % len(val_dataset))

'''
Loss Function
'''
# Define a custom loss function for label smoothing.
class LabelSmoothingCrossEntropy(nn.Layer):
    def __init__(self, smoothing=0.1):
        super().__init__()
        self.smoothing = smoothing

    # Implement the forward pass of label smoothing cross entropy.
    def forward(self, pred, target):
        confidence = 1. - self.smoothing
        log_probs = F.log_softmax(pred, axis=-1)
        idx = paddle.stack([paddle.arange(log_probs.shape[0]), target.astype('int64')], axis=1) # Create index for target.
        nll_loss = paddle.gather_nd(-log_probs, index=idx)
        smooth_loss = paddle.mean(-log_probs, axis=-1)
        loss = confidence * nll_loss + self.smoothing * smooth_loss # Calculate the loss.

        return loss.mean() # Return the mean loss.
    
'''
Training and Validation
'''
# Define the model.
model = SBCFormer_XS(num_classes=num_classes)
print("The structure of the constructed model is listed below:")
paddle.summary(model, (1, 3, 224, 224))

# Define the loss function and optimizer.
criterion = LabelSmoothingCrossEntropy()
scheduler = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=learning_rate, T_max=50000 // batch_size * n_epochs, verbose=False)
optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=scheduler, weight_decay=1e-5)

# Initialize the training parameters.
gate = 0.0
threshold = 0.0
best_acc = 0.0
val_acc = 0.0
loss_record = {'train': {'loss': [], 'iter': []}, 'val': {'loss': [], 'iter': []}}   # for recording loss
acc_record = {'train': {'acc': [], 'iter': []}, 'val': {'acc': [], 'iter': []}}      # for recording accuracy
loss_iter = 0
acc_iter = 0

# Train the model.
for epoch in range(n_epochs):
    # Traning stage.
    model.train()
    train_num = 0.0
    train_loss = 0.0
    val_num = 0.0
    val_loss = 0.0
    accuracy_manager = paddle.metric.Accuracy() # For recording accuracy.
    val_accuracy_manager = paddle.metric.Accuracy()
    print("\n") 
    print("---------- Training Epoch: {}, Current Learning Rate: {:.4f} ----------".format(epoch, optimizer.get_lr()))

    # Training per batch.
    for batch_id, data in enumerate(train_loader):
        x_data, y_data = data
        labels = paddle.unsqueeze(y_data, axis=1)
        logits = model(x_data)
        loss = criterion(logits, y_data)
        acc = accuracy_manager.compute(logits, labels) # Calculate the accuracy.
        accuracy_manager.update(acc) # Update the accuracy.
        current_batch_loss_recorder = loss # Record the loss in another variable.
        current_batch_accuracy_recorder = accuracy_manager # Record the accuracy in another variable.

        # For each 5 iterations, record the training information.
        if batch_id % 5 == 0:
            loss_record['train']['loss'].append(loss.numpy())
            loss_record['train']['iter'].append(loss_iter)
            loss_iter += 1
        print("Batch ID: {}, Current Loss: {:.4f}, Current Acc: {:2.2f}%".format(batch_id, current_batch_loss_recorder.numpy(),current_batch_accuracy_recorder.accumulate()*100))

        # Update parameters.
        loss.backward()
        optimizer.step()
        scheduler.step()
        optimizer.clear_grad()
        train_loss += loss
        train_num += len(y_data)

    # Calculate the average loss and accuracy.
    total_train_loss = (train_loss / train_num) * batch_size
    train_acc = accuracy_manager.accumulate()
    acc_record['train']['acc'].append(train_acc)
    acc_record['train']['iter'].append(acc_iter)
    acc_iter += 1
    # Print the information for this epoch.
    print("---------- Training Epoch: {}, Current Loss: {:.4f}, Current Acc: {:2.2f}% ----------".format(epoch, total_train_loss.numpy(), train_acc*100))

    # Validation stage.
    model.eval()

    # Validation per batch.
    for batch_id, data in enumerate(val_loader):
        x_data, y_data = data
        labels = paddle.unsqueeze(y_data, axis=1)
        with paddle.no_grad():
          logits = model(x_data)
        
        # Calculate the loss and accuracy.
        loss = criterion(logits, y_data)
        acc = val_accuracy_manager.compute(logits, labels)
        val_accuracy_manager.update(acc)
        val_loss += loss
        val_num += len(y_data)

    # Calculate the average loss and accuracy.
    total_val_loss = (val_loss / val_num) * batch_size
    loss_record['val']['loss'].append(total_val_loss.numpy())
    loss_record['val']['iter'].append(loss_iter)
    val_acc = val_accuracy_manager.accumulate()
    acc_record['val']['acc'].append(val_acc)
    acc_record['val']['iter'].append(acc_iter)

    # Print the information for this epoch.
    print("---------- Validation Epoch: {}, Val Loss: {:.4f}, Val Acc: {:2.2f}% ----------".format(epoch, total_val_loss.numpy(), val_acc*100))

    # Save the best model.
    if val_acc > best_acc:
        best_acc = val_acc
        paddle.save(model.state_dict(), os.path.join(work_path, 'best_model.pdparams'))
        paddle.save(optimizer.state_dict(), os.path.join(work_path, 'best_optimizer.pdopt'))

# Save the final model.
print("\n")
print("The best accuracy during training is: {:2.2f}%".format(best_acc*100))
paddle.save(model.state_dict(), os.path.join(work_path, 'final_model.pdparams'))
paddle.save(optimizer.state_dict(), os.path.join(work_path, 'final_optimizer.pdopt'))

'''
Evaluation of Curve Plotting
'''
# Define the function for plotting learning curve.
def plot_learning_curve(record, title='loss', ylabel='CE Loss'):
    # Get the min and max values of y.
    maxtrain = max(map(float, record['train'][title]))
    maxval = max(map(float, record['val'][title]))
    ymax = max(maxtrain, maxval) * 1.1
    mintrain = min(map(float, record['train'][title]))
    minval = min(map(float, record['val'][title]))
    ymin = min(mintrain, minval) * 0.9

    # Get the number of iterations.
    total_steps = len(record['train'][title])
    x_1 = list(map(int, record['train']['iter']))
    x_2 = list(map(int, record['val']['iter']))

    # Plot the learning curve.
    figure(figsize=(10, 6))
    plt.plot(x_1, record['train'][title], c='tab:red', label='train')
    plt.plot(x_2, record['val'][title], c='tab:cyan', label='val')
    plt.ylim(ymin, ymax)
    plt.xlabel('Training steps')
    plt.ylabel(ylabel)
    plt.title('Learning curve of {}'.format(title))
    plt.legend()
    plt.show()

# Plot the learning curve of loss and accuraacy in training and validation.
plot_learning_curve(loss_record, title='loss', ylabel='CE Loss')
plot_learning_curve(acc_record, title='acc', ylabel='Accuracy')

'''
Visualization of Prediction Results
'''
# Import the necessary packages.
import time

# Define the path of model.
work_path = 'HMDD_Model_Python/work/model' # Re-define the path for saving model.
model = SBCFormer_XS(num_classes=num_classes)
model_state_dict = paddle.load(os.path.join(work_path, 'best_model.pdparams'))
model.set_state_dict(model_state_dict)
model.eval()
aa = time.time()

# Predict the validation dataset.
for batch_id, data in enumerate(val_loader):
    x_data, y_data = data
    labels = paddle.unsqueeze(y_data, axis=1)
    with paddle.no_grad():
        logits = model(x_data)
bb = time.time()
print("Throughout:{}".format(int(len(val_dataset)//(bb - aa)))) # FPS.

# Define the function for getting labels.
def get_dataset_labels(labels):
    text_labels = ['000', '030', '045', '060', '090', '300', '315','330']

    return [text_labels[int(i)] for i in labels]

# Define the function for showing images.
def show_images(imgs, num_rows, num_cols, pred=None, gt=None, scale=1.5):
    figsize = (num_cols * scale, num_rows * scale)
    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()

    # Plot the images.
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        if paddle.is_tensor(img):
            ax.imshow(img.numpy())
        else:
            ax.imshow(img)
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if pred or gt:
            ax.set_title("pt: " + pred[i] + "\ngt: " + gt[i])

    return axes

# Define the function for getting labels.
work_path = 'HMDD_Model_Python/work/model' # Re-define the path for saving model.
X, y = next(iter(DataLoader(val_dataset, batch_size=8))) # Get a batch of data.
model = SBCFormer_XS(num_classes=num_classes)
model_state_dict = paddle.load(os.path.join(work_path, 'best_model.pdparams'))
model.set_state_dict(model_state_dict)
model.eval()
logits = model(X)
y_pred = paddle.argmax(logits, -1)
X = paddle.transpose(X, [0, 2, 3, 1])
axes = show_images(X.reshape((8, 224, 224, 3)), 1, 8, pred=get_dataset_labels(y_pred), gt=get_dataset_labels(y)) # Show the prediction results.
plt.show()